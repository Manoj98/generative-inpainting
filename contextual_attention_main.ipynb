{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38ZGtnjJZC26","executionInfo":{"status":"ok","timestamp":1682887176622,"user_tz":240,"elapsed":2291,"user":{"displayName":"Manoj Parmar","userId":"15566864559619598980"}},"outputId":"2290ecf7-33e3-4fb9-d39c-95aa07301fcb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/DL_Project"],"metadata":{"id":"bJVGNVvsZIJa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682887179863,"user_tz":240,"elapsed":310,"user":{"displayName":"Manoj Parmar","userId":"15566864559619598980"}},"outputId":"02c98d79-e355-4750-d529-d6a65c645a80"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DL_Project\n"]}]},{"cell_type":"code","source":["!pip install tensorboardX\n","!pip install pyyaml==5.4.1\n","!pip install deeplake"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPGgGTDSY5Sv","executionInfo":{"status":"ok","timestamp":1682887195076,"user_tz":240,"elapsed":13245,"user":{"displayName":"Manoj Parmar","userId":"15566864559619598980"}},"outputId":"e666777b-e7ca-4785-97a5-afdefac02a29"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6)\n","Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyyaml==5.4.1 in /usr/local/lib/python3.10/dist-packages (5.4.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: deeplake in /usr/local/lib/python3.10/dist-packages (3.3.2)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.26.76)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.22.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from deeplake) (8.4.0)\n","Requirement already satisfied: aioboto3>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from deeplake) (11.1.0)\n","Requirement already satisfied: humbug>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.3.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeplake) (8.1.3)\n","Requirement already satisfied: numcodecs in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.11.0)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.5.6)\n","Requirement already satisfied: pathos in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.3.0)\n","Requirement already satisfied: pyjwt in /usr/local/lib/python3.10/dist-packages (from deeplake) (2.6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deeplake) (4.65.0)\n","Requirement already satisfied: aiobotocore[boto3]==2.5.0 in /usr/local/lib/python3.10/dist-packages (from aioboto3>=10.4.0->deeplake) (2.5.0)\n","Requirement already satisfied: aiohttp>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (3.8.4)\n","Requirement already satisfied: aioitertools>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (0.11.0)\n","Requirement already satisfied: wrapt>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (1.14.1)\n","Requirement already satisfied: botocore<1.29.77,>=1.29.76 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (1.29.76)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->deeplake) (1.0.1)\n","Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3->deeplake) (0.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from humbug>=0.3.1->deeplake) (2.27.1)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from numcodecs->deeplake) (0.4)\n","Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (0.3.6)\n","Requirement already satisfied: ppft>=1.7.6.6 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (1.7.6.6)\n","Requirement already satisfied: multiprocess>=0.70.14 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (0.70.14)\n","Requirement already satisfied: pox>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (0.3.2)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.29.77,>=1.29.76->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (1.26.15)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.29.77,>=1.29.76->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (2.8.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->humbug>=0.3.1->deeplake) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->humbug>=0.3.1->deeplake) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->humbug>=0.3.1->deeplake) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (1.3.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (1.9.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.29.77,>=1.29.76->aiobotocore[boto3]==2.5.0->aioboto3>=10.4.0->deeplake) (1.16.0)\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"rgsvPxv9YyvH","executionInfo":{"status":"ok","timestamp":1682887197303,"user_tz":240,"elapsed":2230,"user":{"displayName":"Manoj Parmar","userId":"15566864559619598980"}}},"outputs":[],"source":["%reload_ext autoreload\n","%autoreload 2\n","\n","import os\n","import random\n","import time\n","import shutil\n","from argparse import ArgumentParser\n","\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","import torchvision.utils as vutils\n","import torchvision.transforms as transforms\n","from tensorboardX import SummaryWriter\n","\n","from trainer import Trainer\n","from data.dataset import Dataset, DeeplakeDataset\n","from utils.tools import get_config, random_bbox, mask_image, is_image_file, default_loader, normalize, get_model_list\n","from utils.logger import get_logger\n","from model.networks import Generator\n","\n","import matplotlib.pyplot as plt\n","import deeplake"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tD4X1dEHYyvK","executionInfo":{"status":"ok","timestamp":1682887197303,"user_tz":240,"elapsed":3,"user":{"displayName":"Manoj Parmar","userId":"15566864559619598980"}},"outputId":"4ae6b6ac-0dec-41cf-ef71-0fa5dfb52d03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tesla T4\n","True\n","1\n"]}],"source":["print(torch.cuda.get_device_name())\n","print(torch.cuda.is_available())\n","print(torch.cuda.device_count())"]},{"cell_type":"markdown","source":["### Train the Model"],"metadata":{"id":"sciEqvo5tiuD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MeWRjya5YyvL"},"outputs":[],"source":["def train():\n","    # args = parser.parse_args()\n","    # config = get_config(args.config)\n","\n","    config_path = 'configs/config.yaml' # Edited by Manoj\n","    config = get_config(config_path)\n","    seed = None\n","\n","    # CUDA configuration\n","    cuda = config['cuda']\n","    device_ids = config['gpu_ids']\n","    if cuda:\n","        os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(i) for i in device_ids)\n","        device_ids = list(range(len(device_ids)))\n","        config['gpu_ids'] = device_ids\n","        cudnn.benchmark = True\n","\n","    # Configure checkpoint path\n","    checkpoint_path = os.path.join('checkpoints',\n","                                   config['dataset_name'],\n","                                   config['mask_type'] + '_' + config['expname'])\n","    print(\"Checkpoint Path is:\", checkpoint_path)\n","    if not os.path.exists(checkpoint_path):\n","        os.makedirs(checkpoint_path)\n","    # shutil.copy(args.config, os.path.join(checkpoint_path, os.path.basename(args.config)))\n","    shutil.copy(config_path, os.path.join(checkpoint_path, os.path.basename(config_path))) # Edited by Manoj\n","    writer = SummaryWriter(logdir=checkpoint_path)\n","    logger = get_logger(checkpoint_path)    # get logger and configure it at the first call\n","\n","    # logger.info(\"Arguments: {}\".format(args))\n","    # Set random seed\n","    if seed is None:\n","        seed = random.randint(1, 10000)\n","    logger.info(\"Random seed: {}\".format(seed))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    if cuda:\n","        torch.cuda.manual_seed_all(seed)\n","\n","    # Log the configuration\n","    logger.info(\"Configuration: {}\".format(config))\n","\n","    try:  # for unexpected error logging\n","        # Load the dataset\n","        logger.info(\"Training on dataset: {}\".format(config['dataset_name']))\n","        # train_dataset = Dataset(data_path=config['train_data_path'],\n","        #                         with_subfolder=config['data_with_subfolder'],\n","        #                         image_shape=config['image_shape'],\n","        #                         random_crop=config['random_crop'])\n","        \n","        train_dataset = DeeplakeDataset(data_path=config['train_data_path'],\n","                        with_subfolder=config['data_with_subfolder'],\n","                        image_shape=config['image_shape'],\n","                        random_crop=config['random_crop'])\n","\n","        # Generate a random subset of indices\n","        random.seed(seed)\n","        num_images = len(train_dataset.data)\n","\n","        subset_indices = random.sample(range(num_images), k=config['data_subset_size'])\n","\n","        # val_dataset = Dataset(data_path=config['val_data_path'],\n","        #                       with_subfolder=config['data_with_subfolder'],\n","        #                       image_size=config['image_size'],\n","        #                       random_crop=config['random_crop'])\n","\n","\n","        # Load DataLoader with the above Random Sample\n","        train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                                   batch_size=config['batch_size'],\n","                                                   shuffle=False,\n","                                                   num_workers=config['num_workers'],\n","                                                   sampler = torch.utils.data.SubsetRandomSampler(subset_indices))\n","        print(\"Total No. of Batches =\", len(train_loader))\n","        \n","        # val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n","        #                                           batch_size=config['batch_size'],\n","        #                                           shuffle=False,\n","        #                                           num_workers=config['num_workers'])\n","\n","        # Define the trainer\n","        trainer = Trainer(config)\n","        # logger.info(\"\\n{}\".format(trainer.netG))\n","        # print(\"NETG done\")\n","        # logger.info(\"\\n{}\".format(trainer.localD))\n","        # print(\"LocalD done\")\n","        # logger.info(\"\\n{}\".format(trainer.globalD))\n","        # print(\"GlobalD done\")\n","\n","        if cuda:\n","            trainer = nn.parallel.DataParallel(trainer, device_ids=device_ids)\n","            trainer_module = trainer.module\n","        else:\n","            trainer_module = trainer\n","\n","        # Get the resume iteration to restart training\n","        start_iteration = trainer_module.resume(checkpoint_path, config['resume']) if config['resume'] else 1\n","\n","        iterable_train_loader = iter(train_loader)\n","\n","        time_count = time.time()\n","\n","        for iteration in range(start_iteration, config['niter'] + 1):\n","        # for iteration in range(5700, config['niter'] + 1):\n","            try:\n","                ground_truth = next(iterable_train_loader)\n","            except StopIteration:\n","                iterable_train_loader = iter(train_loader)\n","                ground_truth = next(iterable_train_loader)\n","            \n","            ## Edited by Manoj\n","            # print(\"Original Image Example\")\n","            # img = ground_truth[0]\n","            # plt.imshow(img.permute(1,2,0))\n","            # plt.show()\n","\n","            # Prepare the inputs\n","            bboxes = random_bbox(config, batch_size=ground_truth.size(0))\n","            x, mask = mask_image(ground_truth, bboxes, config)\n","\n","            ## Edited by Manoj\n","            # print(\"Masked Image Example\")\n","            # img = x[0]\n","            # plt.imshow(img.permute(1,2,0))\n","            # plt.show()\n","\n","            # print(\"Mask Creation\")\n","            # img = mask[0]\n","            # plt.imshow(img.permute(1,2,0))\n","            # plt.show()\n","\n","            if cuda:\n","                x = x.cuda()\n","                mask = mask.cuda()\n","                ground_truth = ground_truth.cuda()\n","\n","            ###### Forward pass ######\n","            compute_g_loss = iteration % config['n_critic'] == 0\n","            losses, inpainted_result, offset_flow = trainer(x, bboxes, mask, ground_truth, compute_g_loss)\n","            # Scalars from different devices are gathered into vectors\n","            for k in losses.keys():\n","                if not losses[k].dim() == 0:\n","                    losses[k] = torch.mean(losses[k])\n","\n","            ###### Backward pass ######\n","            # Update D\n","            trainer_module.optimizer_d.zero_grad()\n","            losses['d'] = losses['wgan_d'] + losses['wgan_gp'] * config['wgan_gp_lambda']\n","            losses['d'].backward()\n","            trainer_module.optimizer_d.step()\n","\n","            # Update G\n","            if compute_g_loss:\n","                trainer_module.optimizer_g.zero_grad()\n","                losses['g'] = losses['l1'] * config['l1_loss_alpha'] \\\n","                              + losses['ae'] * config['ae_loss_alpha'] \\\n","                              + losses['wgan_g'] * config['gan_loss_alpha']\n","                losses['g'].backward()\n","                trainer_module.optimizer_g.step()\n","\n","            # Log and visualization\n","            log_losses = ['l1', 'ae', 'wgan_g', 'wgan_d', 'wgan_gp', 'g', 'd']\n","            if iteration % config['print_iter'] == 0:\n","                time_count = time.time() - time_count\n","                speed = config['print_iter'] / time_count\n","                speed_msg = 'speed: %.2f batches/s ' % speed\n","                time_count = time.time()\n","\n","                message = 'Iter: [%d/%d] ' % (iteration, config['niter'])\n","                for k in log_losses:\n","                    v = losses.get(k, 0.)\n","                    writer.add_scalar(k, v, iteration)\n","                    message += '%s: %.6f ' % (k, v)\n","                message += speed_msg\n","                logger.info(message)\n","\n","            if iteration % (config['viz_iter']) == 0:\n","                viz_max_out = config['viz_max_out']\n","                if x.size(0) > viz_max_out:\n","                    viz_images = torch.stack([x[:viz_max_out], inpainted_result[:viz_max_out],\n","                                              offset_flow[:viz_max_out]], dim=1)\n","                else:\n","                    viz_images = torch.stack([x, inpainted_result, offset_flow], dim=1)\n","                viz_images = viz_images.view(-1, *list(x.size())[1:])\n","                vutils.save_image(viz_images,\n","                                  '%s/niter_%03d.png' % (checkpoint_path, iteration),\n","                                  nrow=3 * 4,\n","                                  normalize=True)\n","\n","            # Save the model\n","            if iteration % config['snapshot_save_iter'] == 0:\n","                # trainer_module.save_model(checkpoint_path, iteration)\n","                trainer_module.save_model(checkpoint_path, 1000) # Keeping 1000 as constant to keep on replacing the same model file\n","\n","    except Exception as e:  # for unexpected error logging\n","        logger.error(\"{}\".format(e))\n","        raise e\n"]},{"cell_type":"code","source":["# train()"],"metadata":{"id":"7NyQnIZpdclJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Evaluation"],"metadata":{"id":"id7IEWHqtmws"}},{"cell_type":"code","source":["def test_single(image = \"/content/drive/MyDrive/DL_Project/examples/places/images/image0.jpg\", \n","                mask = None, \n","                output = \"/content/drive/MyDrive/DL_Project/examples/places/output/image0.jpg\",\n","                masked_output_image = '/content/drive/MyDrive/DL_Project/examples/places/masks/image0.jpg'):\n","    \n","    \"\"\"\n","    Function to evaluate the generative inpainting model on a single test image.\n","    image : path to the image\n","    mask : path to the input mask. If None, then random mask is generated.\n","    output : Path to store the output image\n","    masked_image_output: Path to store the masked image\n","    \"\"\"\n","    \n","    # args = parser.parse_args()\n","    # config = get_config(args.config)\n","\n","    config_path = 'configs/config.yaml'\n","    config = get_config(config_path)\n","    seed = 200\n","\n","    # CUDA configuration\n","    cuda = config['cuda']\n","    device_ids = config['gpu_ids']\n","    if cuda:\n","        os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(i) for i in device_ids)\n","        device_ids = list(range(len(device_ids)))\n","        config['gpu_ids'] = device_ids\n","        cudnn.benchmark = True\n","\n","    # print(\"Arguments: {}\".format(args))\n","\n","    # Set random seed\n","    if seed is None:\n","        seed = random.randint(1, 10000)\n","    print(\"Random seed: {}\".format(seed))\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    if cuda:\n","        torch.cuda.manual_seed_all(seed)\n","\n","    print(\"Configuration: {}\".format(config))\n","\n","    try:  # for unexpected error logging\n","        with torch.no_grad():   # enter no grad context\n","            if is_image_file(image):\n","                if mask and is_image_file(mask):\n","                    # Test a single masked image with a given mask\n","                    x = default_loader(image)\n","                    mask = default_loader(mask)\n","                    x = transforms.Resize(config['image_shape'][:-1])(x)\n","                    x = transforms.CenterCrop(config['image_shape'][:-1])(x)\n","                    mask = transforms.Resize(config['image_shape'][:-1])(mask)\n","                    mask = transforms.CenterCrop(config['image_shape'][:-1])(mask)\n","                    x = transforms.ToTensor()(x)\n","                    mask = transforms.ToTensor()(mask)[0].unsqueeze(dim=0)\n","                    x = normalize(x)\n","                    x = x * (1. - mask)\n","                    x = x.unsqueeze(dim=0)\n","                    mask = mask.unsqueeze(dim=0)\n","                elif mask:\n","                    raise TypeError(\"{} is not an image file.\".format(mask))\n","                else:\n","                    # Test a single ground-truth image with a random mask\n","                    ground_truth = default_loader(image)\n","                    ground_truth = transforms.Resize(config['image_shape'][:-1])(ground_truth)\n","                    ground_truth = transforms.CenterCrop(config['image_shape'][:-1])(ground_truth)\n","                    ground_truth = transforms.ToTensor()(ground_truth)\n","                    ground_truth = normalize(ground_truth)\n","                    ground_truth = ground_truth.unsqueeze(dim=0)\n","                    bboxes = random_bbox(config, batch_size=ground_truth.size(0))\n","                    x, mask = mask_image(ground_truth, bboxes, config)\n","\n","                # Set checkpoint path\n","                # if not checkpoint_path:\n","                checkpoint_path = os.path.join('checkpoints',\n","                                                config['dataset_name'],\n","                                                config['mask_type'] + '_' + config['expname'])\n","                # else:\n","                #     checkpoint_path = checkpoint_path\n","\n","                # Define the trainer\n","                netG = Generator(config['netG'], cuda, device_ids)\n","                # Resume weight\n","                # last_model_name = get_model_list(checkpoint_path, \"gen\", iteration=args.iter)\n","                last_model_name = get_model_list(checkpoint_path, \"gen\", iteration=1000) # Kept 1000 as static iteration name for model to keep on replacing the same model\n","                netG.load_state_dict(torch.load(last_model_name))\n","                model_iteration = int(last_model_name[-11:-3])\n","                print(\"Resume from {} at iteration {}\".format(checkpoint_path, model_iteration))\n","\n","                if cuda:\n","                    netG = nn.parallel.DataParallel(netG, device_ids=device_ids)\n","                    x = x.cuda()\n","                    mask = mask.cuda()\n","\n","                # Inference\n","                x1, x2, offset_flow = netG(x, mask)\n","                inpainted_result = x2 * mask + x * (1. - mask)\n","\n","                # Save final image\n","                vutils.save_image(inpainted_result, output, padding=0, normalize=True)\n","                print(\"Saved the inpainted result to {}\".format(output))\n","\n","                # Save mask\n","                vutils.save_image(x, masked_output_image, padding=0, normalize=True)\n","                print(\"Saved the masked result to {}\".format(masked_output_image))\n","\n","                # if args.flow:\n","                #     vutils.save_image(offset_flow, args.flow, padding=0, normalize=True)\n","                #     print(\"Saved offset flow to {}\".format(args.flow))\n","            else:\n","                raise TypeError(\"{} is not an image file.\".format)\n","        # exit no grad context\n","    except Exception as e:  # for unexpected error logging\n","        print(\"Error: {}\".format(e))\n","        raise e"],"metadata":{"id":"uvIVUe81tRY-","executionInfo":{"status":"ok","timestamp":1682891082097,"user_tz":240,"elapsed":324,"user":{"displayName":"Manoj Parmar","userId":"15566864559619598980"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def test_all_images(input_dir, output_dir, mask_output_dir):\n","    \"\"\"\n","    Generate inpainted output images for all images in the input directory and store in the output directory\n","    input_dir: path to the input directory\n","    output_dir: path to the output directory \n","    masked_output_dir: path to the masked image\n","    \"\"\"\n","\n","    # create output directory if it does not exist\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    # loop through each file in input directory\n","    for i, file_name in enumerate(os.listdir(input_dir)):\n","        # Generate image input and output path\n","        image_path = os.path.join(input_dir, file_name)\n","        output_image_path = os.path.join(output_dir, file_name)\n","        output_masked_path = os.path.join(mask_output_dir, file_name)\n","        print(i, file_name)\n","        test_single(image = image_path, mask = None, output = output_image_path, masked_output_image = output_masked_path)\n","\n"],"metadata":{"id":"ADtym0Z0tRTv","executionInfo":{"status":"ok","timestamp":1682891153841,"user_tz":240,"elapsed":307,"user":{"displayName":"Manoj Parmar","userId":"15566864559619598980"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["#### Run the evaluation\n","\n","## Run all test images\n","\n","# set input and output paths\n","input_dir = \"/content/drive/MyDrive/DL_Project/examples/places/images\"\n","output_dir = '/content/drive/MyDrive/DL_Project/examples/places/output'\n","mask_output_dir = '/content/drive/MyDrive/DL_Project/examples/places/masks'\n","\n","test_all_images(input_dir, output_dir, mask_output_dir) \n","\n","\n","## Run one single test image\n","# image_path = \"/content/drive/MyDrive/DL_Project/data/places/places_1.jpg\"\n","# output_path = \"/content/drive/MyDrive/DL_Project/examples/places/output_1.png\"\n","\n","# test_single(image = image_path, mask = None, output = output_path)"],"metadata":{"id":"_MHxFsQC_uim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N2UqS9S0_ugS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dDXQLyMV8Cpb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Rough"],"metadata":{"id":"NS00Z9ZP7ybj"}},{"cell_type":"code","source":[],"metadata":{"id":"WvsNr6-57sVb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# import glob\n","# import numpy as np\n","# from PIL import Image\n","\n","# # Set the input and output directories\n","# input_dir = \"/content/drive/MyDrive/DL_Project/examples/places/images_npy\"\n","# output_dir = '/content/drive/MyDrive/DL_Project/examples/places/images'\n","\n","# # Find all .npy files in the input directory\n","# npy_files = glob.glob(os.path.join(input_dir, '*.npy'))\n","\n","# # Loop through all .npy files and convert them to .jpg\n","# for i, npy_file in enumerate(npy_files):\n","#     # Load the .npy file as a NumPy array\n","#     try:\n","#       # print(i, \"Image:\", npy_file)\n","#       npy_array = np.load(npy_file)\n","#       # Convert the NumPy array to a PIL image\n","#       pil_image = Image.fromarray(np.uint8(npy_array))\n","\n","#       # Get the filename without the extension\n","#       file_name = os.path.splitext(os.path.basename(npy_file))[0]\n","\n","#       # Save the PIL image as a .jpg file in the output directory\n","#       pil_image.save(os.path.join(output_dir, file_name + '.jpg'))\n","#     except:\n","#       print(npy_file)\n","#       continue"],"metadata":{"id":"QZ7i68a6WbcY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682889904920,"user_tz":240,"elapsed":1408,"user":{"displayName":"Manoj Parmar","userId":"15566864559619598980"}},"outputId":"b96d998a-057a-4311-ec2a-c7f38797fcbd"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DL_Project/examples/places/images_npy/image128.npy\n","/content/drive/MyDrive/DL_Project/examples/places/images_npy/image260.npy\n","/content/drive/MyDrive/DL_Project/examples/places/images_npy/image301.npy\n","/content/drive/MyDrive/DL_Project/examples/places/images_npy/image365.npy\n","/content/drive/MyDrive/DL_Project/examples/places/images_npy/image343.npy\n","/content/drive/MyDrive/DL_Project/examples/places/images_npy/image399.npy\n","/content/drive/MyDrive/DL_Project/examples/places/images_npy/image47.npy\n","/content/drive/MyDrive/DL_Project/examples/places/images_npy/image60.npy\n","/content/drive/MyDrive/DL_Project/examples/places/images_npy/image56.npy\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RT2EmCk2xnxa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1oy0D8zaS6zR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ds = deeplake.load(\"hub://activeloop/places205\")\n","\n","# from torchvision import transforms\n","\n","# tform = transforms.Compose([\n","#     transforms.ToTensor(), # Must convert to pytorch tensor for subsequent operations to run\n","# ])\n","\n","# train_loader = ds.dataloader()\\\n","#     .transform({'images': tform, 'labels': None})\\\n","#     .batch(2)\\\n","#     .shuffle()\\\n","#     .pytorch(decode_method={'images': 'pil'})\n","\n","\n","# for i, sample in enumerate(train_loader):\n","#     if i==0:\n","#       print(i, sample)"],"metadata":{"id":"wcLf9VX3S6wq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WuxbBdqYS6uK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","# import random\n","# from deeplake.core.tensor import Tensor\n","# import deeplake\n","\n","# # Path to the directory containing the Places2 dataset\n","# dataset = deeplake.load(\"hub://activeloop/places205\")"],"metadata":{"id":"8psVNZCRhiXZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #Get the total number of images in the dataset\n","\n","# random.seed(0)\n","# num_images = len(dataset)\n","\n","# # Generate a random subset of indices\n","# subset_indices = random.sample(range(num_images), k=100)\n","# print(subset_indices)\n","\n","# data_loader = torch.utils.data.DataLoader(dataset=dataset,\n","#                                                    batch_size=4,\n","#                                                    shuffle=False,\n","#                                                    num_workers=2,\n","#                                                    sampler = torch.utils.data.SubsetRandomSampler(subset_indices))\n","\n","\n","# data_loader\n","# # img = subset_data[0].images.numpy()\n","# # plt.imshow(img)\n","# # plt.show()"],"metadata":{"id":"ynGIsBdVG8NW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #Get the total number of images in the dataset\n","\n","# def subset_data(self, subset_size = 100, seed = 0):\n","#   \"\"\"Randomly subset data from the original Dataset\"\n","#   subset_size : Length of subset\n","#   seed: Seed to reproduce the results\n","# \"\"\"\n","\n","#   random.seed(seed)\n","#   num_images = self.__len__()\n","\n","#   # Generate a random subset of indices\n","#   subset_indices = random.sample(range(num_images), k=subset_size)\n","\n","#   # Retrieve the images and labels corresponding to the subset indices\n","#   subset_data = []\n","#   for i in subset_indices:\n","#       img, label = self.data[i].images, self.data[i].labels\n","#       subset_data.append((img, label))\n","\n","#   # Print the size of the subset\n","#   print(\"Size of the subset: \", len(subset_data))\n","  \n","#   return subset_data"],"metadata":{"id":"wxkHhOQPxyZ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Hzu3mZqQxySd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Vs5mgknQxyQC"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"orig_nbformat":4,"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}